{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14774e11-bbbc-4ef9-90d2-735bc68f10ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: yfinance in /opt/anaconda3/lib/python3.12/site-packages (0.2.51)\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: scikeras in /opt/anaconda3/lib/python3.12/site-packages (0.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (5.2.1)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.12/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install pandas numpy scikit-learn matplotlib yfinance tensorflow scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8882ecca-13c5-4efa-8651-91d2214bfb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 16:45:11.457407: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from scikeras.wrappers import KerasRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828abf7d-90ae-408d-abb9-f57146d3b539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download Apple stock data\n",
    "data = yf.download(\"AAPL\", start=\"2015-01-01\", end=\"2023-01-01\")\n",
    "\n",
    "# Calculate moving averages and relative price change\n",
    "data['SMA_10'] = data['Close'].rolling(window=10).mean()\n",
    "data['SMA_50'] = data['Close'].rolling(window=50).mean()\n",
    "data['Price_Change'] = data['Close'].pct_change()\n",
    "\n",
    "# set target as next days close\n",
    "data['Target'] = data['Close'].shift(-1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e81d38c-90be-4876-803c-d61f54599e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.39427465 -0.36631717  0.44833143]\n",
      " [ 0.8294438   0.87237632  1.55648348]\n",
      " [-0.62213843 -0.65672014 -0.16868121]\n",
      " ...\n",
      " [-0.46332114 -0.50801801  0.29107062]\n",
      " [ 1.14670756  0.97596016 -0.75594717]\n",
      " [-0.43484713 -0.43296642  0.84760288]]\n",
      "Training samples: 1571, Testing samples: 393\n"
     ]
    }
   ],
   "source": [
    "#scale data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X = data[['SMA_10', 'SMA_50', 'Price_Change']]\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "y = data['Target']\n",
    "y_scaled = scaler_y.fit_transform(y.to_frame())\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train)\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5377aef-56d5-4773-a5f1-a833421cf2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeatable way to create the model \n",
    "def create_ann(neurons=32, activation='relu', optimizer='admin'):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))  #input structure\n",
    "    model.add(Dense(neurons, activation=activation)) # hidden layer\n",
    "    model.add(Dense(neurons, activation=activation)) # hidden layer\n",
    "    model.add(Dense(1)) #output\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c8245-e4a6-43de-b40a-1266e269a4b5",
   "metadata": {},
   "source": [
    "<h1> GridSearch setup </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce60ecbc-1e3d-4ab2-8b31-92bc1ff246a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defone model parameters and create model\n",
    "param_grid = {\n",
    "    'model__neurons': [16, 32, 64, 128],\n",
    "    'model__activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'model__optimizer': ['adam', 'sgd'],\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [50, 100, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fd97d0-1bde-4124-9d18-b549f2900716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 16:45:32.527059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-29 16:45:32.576280: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-29 16:45:32.617983: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-29 16:45:32.715913: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3; 1/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=adam[CV 1/3; 2/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=sgd\n",
      "\n",
      "[CV 1/3; 1/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=adam\n",
      "[CV 2/3; 1/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=adam\n",
      "[CV 1/3; 2/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=sgd;, score=-0.049 total time=  22.1s\n",
      "[CV 2/3; 2/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=sgd\n",
      "[CV 1/3; 1/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=adam;, score=-0.037 total time=  25.7s\n",
      "[CV 3/3; 2/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=sgd\n",
      "[CV 2/3; 1/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=adam;, score=-0.034 total time=  26.1s\n",
      "[CV 3/3; 1/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=adam;, score=-0.039 total time=  26.1s\n",
      "[CV 1/3; 3/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=adam\n",
      "[CV 2/3; 3/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=adam\n",
      "[CV 2/3; 2/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=sgd;, score=-0.043 total time=  26.5s\n",
      "[CV 3/3; 3/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=adam\n",
      "[CV 3/3; 2/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=16, model__optimizer=sgd;, score=-0.049 total time=  24.7s\n",
      "[CV 1/3; 4/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=sgd\n",
      "[CV 2/3; 3/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=adam;, score=-0.037 total time=  29.8s\n",
      "[CV 2/3; 4/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=sgd\n",
      "[CV 1/3; 3/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=adam;, score=-0.038 total time=  30.4s\n",
      "[CV 3/3; 4/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=sgd\n",
      "[CV 1/3; 4/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=sgd;, score=-0.044 total time=  24.7s\n",
      "[CV 1/3; 5/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=adam\n",
      "[CV 3/3; 3/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=adam;, score=-0.041 total time=  26.7s\n",
      "[CV 2/3; 5/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=adam\n",
      "[CV 2/3; 4/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=sgd;, score=-0.040 total time=  21.0s\n",
      "[CV 3/3; 5/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=adam\n",
      "[CV 3/3; 4/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=32, model__optimizer=sgd;, score=-0.053 total time=  22.6s\n",
      "[CV 1/3; 6/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=sgd\n",
      "[CV 1/3; 6/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=sgd;, score=-0.045 total time=  25.2s\n",
      "[CV 2/3; 6/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=sgd\n",
      "[CV 2/3; 5/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=adam;, score=-0.034 total time=  29.6s\n",
      "[CV 3/3; 6/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=sgd\n",
      "[CV 1/3; 5/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=adam;, score=-0.042 total time=  30.5s\n",
      "[CV 1/3; 7/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=adam\n",
      "[CV 3/3; 5/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=adam;, score=-0.041 total time=  29.3s\n",
      "[CV 2/3; 7/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=adam\n",
      "[CV 3/3; 6/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=sgd;, score=-0.047 total time=  21.3s\n",
      "[CV 3/3; 7/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=adam\n",
      "[CV 2/3; 6/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=64, model__optimizer=sgd;, score=-0.036 total time=  22.1s\n",
      "[CV 1/3; 8/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=sgd\n",
      "[CV 1/3; 7/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=adam;, score=-0.039 total time=  24.4s\n",
      "[CV 2/3; 8/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=sgd\n",
      "[CV 2/3; 7/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=adam;, score=-0.049 total time=  23.9s\n",
      "[CV 3/3; 8/144] START batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=sgd\n",
      "[CV 1/3; 8/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=sgd;, score=-0.042 total time=  20.8s\n",
      "[CV 1/3; 9/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=adam\n",
      "[CV 3/3; 7/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=adam;, score=-0.045 total time=  22.7s\n",
      "[CV 2/3; 9/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=adam\n",
      "[CV 2/3; 8/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=sgd;, score=-0.039 total time=  20.6s\n",
      "[CV 3/3; 9/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=adam\n",
      "[CV 3/3; 8/144] END batch_size=16, epochs=50, model__activation=relu, model__neurons=128, model__optimizer=sgd;, score=-0.047 total time=  22.4s\n",
      "[CV 1/3; 10/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=sgd\n",
      "[CV 1/3; 9/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=adam;, score=-0.041 total time=  23.6s\n",
      "[CV 2/3; 10/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=sgd\n",
      "[CV 2/3; 9/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=adam;, score=-0.044 total time=  22.1s\n",
      "[CV 3/3; 10/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=sgd\n",
      "[CV 3/3; 9/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=adam;, score=-0.038 total time=  21.0s\n",
      "[CV 1/3; 11/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=adam\n",
      "[CV 1/3; 10/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=sgd;, score=-0.049 total time=  20.1s\n",
      "[CV 2/3; 11/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=adam\n",
      "[CV 2/3; 10/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=sgd;, score=-0.042 total time=  17.8s\n",
      "[CV 3/3; 11/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=adam\n",
      "[CV 3/3; 10/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=16, model__optimizer=sgd;, score=-0.045 total time=  18.1s\n",
      "[CV 1/3; 12/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=sgd\n",
      "[CV 1/3; 11/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=adam;, score=-0.037 total time=  20.5s\n",
      "[CV 2/3; 12/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=sgd\n",
      "[CV 2/3; 11/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=adam;, score=-0.036 total time=  20.7s\n",
      "[CV 3/3; 12/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=sgd\n",
      "[CV 1/3; 12/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=sgd;, score=-0.044 total time=  17.8s\n",
      "[CV 1/3; 13/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=adam\n",
      "[CV 3/3; 11/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=adam;, score=-0.040 total time=  19.9s\n",
      "[CV 2/3; 13/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=adam\n",
      "[CV 2/3; 12/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=sgd;, score=-0.041 total time=  16.8s\n",
      "[CV 3/3; 13/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=adam\n",
      "[CV 3/3; 12/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=32, model__optimizer=sgd;, score=-0.042 total time=  17.2s\n",
      "[CV 1/3; 14/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=sgd\n",
      "[CV 1/3; 13/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=adam;, score=-0.044 total time=  22.5s\n",
      "[CV 2/3; 14/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=sgd\n",
      "[CV 1/3; 14/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=sgd;, score=-0.037 total time=  19.4s\n",
      "[CV 3/3; 14/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=sgd\n",
      "[CV 3/3; 13/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=adam;, score=-0.042 total time=  21.9s\n",
      "[CV 1/3; 15/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=adam\n",
      "[CV 2/3; 13/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=adam;, score=-0.036 total time=  22.5s\n",
      "[CV 2/3; 15/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=adam\n",
      "[CV 3/3; 14/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=sgd;, score=-0.044 total time=  17.5s\n",
      "[CV 3/3; 15/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=adam\n",
      "[CV 2/3; 14/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=64, model__optimizer=sgd;, score=-0.040 total time=  18.5s\n",
      "[CV 1/3; 16/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=sgd\n",
      "[CV 2/3; 15/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=adam;, score=-0.044 total time=  23.3s\n",
      "[CV 2/3; 16/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=sgd\n",
      "[CV 1/3; 15/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=adam;, score=-0.039 total time=  24.7s\n",
      "[CV 3/3; 16/144] START batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=sgd\n",
      "[CV 1/3; 16/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=sgd;, score=-0.038 total time=  21.8s\n",
      "[CV 1/3; 17/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=adam\n",
      "[CV 3/3; 15/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=adam;, score=-0.038 total time=  24.0s\n",
      "[CV 2/3; 17/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=adam\n",
      "[CV 2/3; 16/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=sgd;, score=-0.038 total time=  19.1s\n",
      "[CV 3/3; 17/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=adam\n",
      "[CV 3/3; 16/144] END batch_size=16, epochs=50, model__activation=tanh, model__neurons=128, model__optimizer=sgd;, score=-0.042 total time=  21.6s\n",
      "[CV 1/3; 18/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=sgd\n",
      "[CV 1/3; 17/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=adam;, score=-0.054 total time=  21.8s\n",
      "[CV 2/3; 18/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=sgd\n",
      "[CV 2/3; 17/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=adam;, score=-0.058 total time=  21.9s\n",
      "[CV 3/3; 18/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=sgd\n",
      "[CV 1/3; 18/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=sgd;, score=-0.073 total time=  19.0s\n",
      "[CV 1/3; 19/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=adam\n",
      "[CV 3/3; 17/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=adam;, score=-0.058 total time=  23.5s\n",
      "[CV 2/3; 19/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=adam\n",
      "[CV 2/3; 18/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=sgd;, score=-0.065 total time=  19.5s\n",
      "[CV 3/3; 19/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=adam\n",
      "[CV 3/3; 18/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=16, model__optimizer=sgd;, score=-0.070 total time=  20.0s\n",
      "[CV 1/3; 20/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=sgd\n",
      "[CV 1/3; 19/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=adam;, score=-0.049 total time=  21.6s\n",
      "[CV 2/3; 20/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=sgd\n",
      "[CV 2/3; 19/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=adam;, score=-0.050 total time=  21.6s\n",
      "[CV 3/3; 20/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=sgd\n",
      "[CV 1/3; 20/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=sgd;, score=-0.058 total time=  19.0s\n",
      "[CV 1/3; 21/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=adam\n",
      "[CV 3/3; 19/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=adam;, score=-0.057 total time=  21.5s\n",
      "[CV 2/3; 21/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=adam\n",
      "[CV 2/3; 20/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=sgd;, score=-0.060 total time=  17.7s\n",
      "[CV 3/3; 21/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=adam\n",
      "[CV 3/3; 20/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=32, model__optimizer=sgd;, score=-0.066 total time=  17.6s\n",
      "[CV 1/3; 22/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=sgd\n",
      "[CV 2/3; 21/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=adam;, score=-0.038 total time=  20.7s\n",
      "[CV 2/3; 22/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=sgd\n",
      "[CV 1/3; 21/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=adam;, score=-0.043 total time=  21.4s\n",
      "[CV 3/3; 22/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=sgd\n",
      "[CV 1/3; 22/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=sgd;, score=-0.059 total time=  19.0s\n",
      "[CV 1/3; 23/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=adam\n",
      "[CV 3/3; 21/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=adam;, score=-0.044 total time=  20.9s\n",
      "[CV 2/3; 23/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=adam\n",
      "[CV 2/3; 22/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=sgd;, score=-0.058 total time=  17.7s\n",
      "[CV 3/3; 23/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=adam\n",
      "[CV 3/3; 22/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=64, model__optimizer=sgd;, score=-0.056 total time=  18.2s\n",
      "[CV 1/3; 24/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=sgd\n",
      "[CV 1/3; 23/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=adam;, score=-0.039 total time=  21.7s\n",
      "[CV 2/3; 24/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=sgd\n",
      "[CV 2/3; 23/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=adam;, score=-0.036 total time=  20.9s\n",
      "[CV 3/3; 24/144] START batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=sgd\n",
      "[CV 1/3; 24/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=sgd;, score=-0.059 total time=  21.5s\n",
      "[CV 1/3; 25/144] START batch_size=16, epochs=100, model__activation=relu, model__neurons=16, model__optimizer=adam\n",
      "[CV 3/3; 23/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=adam;, score=-0.050 total time=  23.2s\n",
      "[CV 2/3; 25/144] START batch_size=16, epochs=100, model__activation=relu, model__neurons=16, model__optimizer=adam\n",
      "[CV 3/3; 24/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=sgd;, score=-0.063 total time=  20.5s\n",
      "[CV 3/3; 25/144] START batch_size=16, epochs=100, model__activation=relu, model__neurons=16, model__optimizer=adam\n",
      "[CV 2/3; 24/144] END batch_size=16, epochs=50, model__activation=sigmoid, model__neurons=128, model__optimizer=sgd;, score=-0.051 total time=  22.1s\n",
      "[CV 1/3; 26/144] START batch_size=16, epochs=100, model__activation=relu, model__neurons=16, model__optimizer=sgd\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m      7\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      8\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m                   \u001b[38;5;66;03m# Use all available cores\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Perform grid search on training data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     18\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(grid_search\u001b[38;5;241m.\u001b[39mcv_results_)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1014\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    961\u001b[0m         )\n\u001b[1;32m    962\u001b[0m     )\n\u001b[0;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    966\u001b[0m         clone(base_estimator),\n\u001b[1;32m    967\u001b[0m         X,\n\u001b[1;32m    968\u001b[0m         y,\n\u001b[1;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    975\u001b[0m     )\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[1;32m    979\u001b[0m     )\n\u001b[1;32m    980\u001b[0m )\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "model = KerasRegressor(model=create_ann, verbose=0) #keras regressor is a wrapper to us scikit learn gid search\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                       # cross-validation\n",
    "    scoring='neg_mean_absolute_error',         # Use mse as scoring\n",
    "    verbose=1,\n",
    "    n_jobs=-1                   # Use all available cores\n",
    ")\n",
    "\n",
    "# Perform grid search on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a398f40d-ac27-45ab-924f-df3f3123dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(grid_search.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "for i, row in results_df.iterrows():\n",
    "    print(f\"Rank {row['rank_test_score']}:\")\n",
    "    print(f\"Parameters: {row['params']}\")\n",
    "    print(f\"Mean Test Score: {row['mean_test_score']:.4f}\")\n",
    "    print(f\"Std Dev of Test Score: {row['std_test_score']:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78022503-45c0-4bca-a1bf-23df289afadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best model to predict\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "final_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the final model\n",
    "mae = mean_absolute_error(y_test, final_predictions)\n",
    "mse = mean_squared_error(y_test, final_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Final Model MAE: {mae}\")\n",
    "print(f\"Final Model RMSE: {rmse}\")\n",
    "\n",
    "# Visualize Predictions vs. Actual Outcomes\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, final_predictions, alpha=0.7, color='b', label='Predicted vs Actual')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')  # Diagonal line\n",
    "plt.title('Actual vs Predicted Values', fontsize=14)\n",
    "plt.xlabel('Actual Values', fontsize=12)\n",
    "plt.ylabel('Predicted Values', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7401708b-9a55-45aa-8f40-d0db293bbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to predict more recent ones\n",
    "stock = yf.Ticker('AAPL')\n",
    "data_to_predict = yf.download(\"AAPL\", start=\"2024-01-01\", end=\"2024-06-01\")\n",
    "data_to_predict['SMA_10'] = data_to_predict['Close'].rolling(window=10).mean()\n",
    "data_to_predict['SMA_50'] = data_to_predict['Close'].rolling(window=50).mean()\n",
    "data_to_predict['Price_Change'] = data_to_predict['Close'].pct_change()\n",
    "data_to_predict['Target'] = data_to_predict['Close'].shift(-1)\n",
    "data_to_predict.dropna(inplace=True)\n",
    "\n",
    "X = data_to_predict[['SMA_10', 'SMA_50', 'Price_Change']]\n",
    "Y = data_to_predict['Target']\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "Y_scaled = scaler_y.fit_transform(Y.to_frame())\n",
    "\n",
    "final_predictions = final_model.predict(X_scaled)\n",
    "\n",
    "mae = mean_absolute_error(Y_scaled, final_predictions)\n",
    "mse = mean_squared_error(Y_scaled, final_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Final Model MAE: {mae}\")\n",
    "print(f\"Final Model RMSE: {rmse}\")\n",
    "\n",
    "# Visualize Predictions vs. Actual Outcomes\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(Y_scaled, final_predictions, alpha=0.7, color='b', label='Predicted vs Actual')\n",
    "plt.plot([Y_scaled.min(), Y_scaled.max()], [Y_scaled.min(), Y_scaled.max()], 'r--', lw=2, label='Perfect Prediction')  # Diagonal line\n",
    "plt.title('Actual vs Predicted Values', fontsize=14)\n",
    "plt.xlabel('Actual Values', fontsize=12)\n",
    "plt.ylabel('Predicted Values', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
