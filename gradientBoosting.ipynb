{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14774e11-bbbc-4ef9-90d2-735bc68f10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy scikit-learn matplotlib yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8882ecca-13c5-4efa-8651-91d2214bfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "from graphing import graph_normal, show_results, graph_line\n",
    "from results import get_num_correct_direction_difference\n",
    "from get_data import get_apple_stock_split , get_recent_apple_stock_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828abf7d-90ae-408d-abb9-f57146d3b539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1772, Testing samples: 444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "\n",
    "DAYS_LAG = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_apple_stock_split(DAYS_LAG)\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
    "\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "y_train = scaler_Y.fit_transform(y_train)\n",
    "\n",
    "X_test = scaler_X.transform(X_test)\n",
    "y_test = scaler_Y.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c8245-e4a6-43de-b40a-1266e269a4b5",
   "metadata": {},
   "source": [
    "<h1> GridSearch setup </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce60ecbc-1e3d-4ab2-8b31-92bc1ff246a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different hyperparameters\n",
    "param_dist = {\n",
    "    'learning_rate': uniform(0.01, 0.3),           # Shrinks the contribution of each tree\n",
    "    'max_iter': randint(100, 500),                 # Number of boosting rounds\n",
    "    'max_depth': randint(3, 10),                   # Maximum depth of trees\n",
    "    'min_samples_leaf': randint(10, 50),           # Minimum number of samples at a leaf node\n",
    "    'l2_regularization': uniform(0.0, 1.0),         # L2 regularization to prevent overfitting\n",
    "    'max_bins': randint(128, 256),                 # Number of bins for histogram binning\n",
    "    'scoring': ['loss', 'neg_root_mean_squared_error']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94fd97d0-1bde-4124-9d18-b549f2900716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "model = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    cv=3,                       # cross-validation\n",
    "    scoring='neg_mean_squared_error',         # Use mse as scoring\n",
    "    verbose=4,\n",
    "    n_jobs=-1,\n",
    "    n_iter=100,  # <- increase this number for more fits\n",
    ")\n",
    "\n",
    "# Perform grid search on training data\n",
    "grid_search.fit(X_train, y_train.ravel())\n",
    "\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a398f40d-ac27-45ab-924f-df3f3123dd53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show_results(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5522ac5-fffe-4e3b-a56f-d495e0532e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model RMSE: 1.7236815046379101\n",
      "Final Model MAE: 0.969372496950562\n"
     ]
    }
   ],
   "source": [
    "# use best model to predict test data\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test data\n",
    "predictions = scaler_Y.inverse_transform(final_model.predict(X_test).reshape(-1,1))\n",
    "actual = scaler_Y.inverse_transform(y_test)\n",
    "\n",
    "mae = mean_absolute_error(actual, predictions)\n",
    "mse = mean_squared_error(actual, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Final Model RMSE: {rmse}\")\n",
    "print(f\"Final Model MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8324c710-6bc3-42eb-aeec-f3f7c6d1c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to DataFrame, shape must be (202, 1): given (444, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_1961/3196995111.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m mae = mean_absolute_error(y, predictions)\n\u001b[32m      9\u001b[39m mse = mean_squared_error(y, predictions)\n\u001b[32m     10\u001b[39m rmse = np.sqrt(mse)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m mape = np.abs((y - predictions)/y_test).mean() * \u001b[32m100\u001b[39m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m print(f\"RMSE: {rmse}\")\n\u001b[32m     14\u001b[39m print(f\"MAE: {mae}\")\n",
      "\u001b[32m/mnt/c/Users/kenan/dev/university_final_year_project/venv_linux/lib/python3.12/site-packages/pandas/core/ops/common.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m NotImplemented\n\u001b[32m     73\u001b[39m \n\u001b[32m     74\u001b[39m         other = item_from_zerodim(other)\n\u001b[32m     75\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m method(self, other)\n",
      "\u001b[32m/mnt/c/Users/kenan/dev/university_final_year_project/venv_linux/lib/python3.12/site-packages/pandas/core/arraylike.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    208\u001b[39m     @unpack_zerodim_and_defer(\u001b[33m\"__truediv__\"\u001b[39m)\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __truediv__(self, other):\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self._arith_method(other, operator.truediv)\n",
      "\u001b[32m/mnt/c/Users/kenan/dev/university_final_year_project/venv_linux/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   7906\u001b[39m \n\u001b[32m   7907\u001b[39m         axis: Literal[\u001b[32m1\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[32m   7908\u001b[39m         other = ops.maybe_prepare_scalar_for_op(other, (self.shape[axis],))\n\u001b[32m   7909\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7910\u001b[39m         self, other = self._align_for_op(other, axis, flex=\u001b[38;5;28;01mTrue\u001b[39;00m, level=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   7911\u001b[39m \n\u001b[32m   7912\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(all=\u001b[33m\"ignore\"\u001b[39m):\n\u001b[32m   7913\u001b[39m             new_data = self._dispatch_frame_op(other, op, axis=axis)\n",
      "\u001b[32m/mnt/c/Users/kenan/dev/university_final_year_project/venv_linux/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, other, axis, flex, level)\u001b[39m\n\u001b[32m   8165\u001b[39m                     \u001b[38;5;66;03m# Broadcast along rows\u001b[39;00m\n\u001b[32m   8166\u001b[39m                     right = to_series(right[\u001b[32m0\u001b[39m, :])\n\u001b[32m   8167\u001b[39m \n\u001b[32m   8168\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m8169\u001b[39m                     raise ValueError(\n\u001b[32m   8170\u001b[39m                         \u001b[33m\"Unable to coerce to DataFrame, shape \"\u001b[39m\n\u001b[32m   8171\u001b[39m                         f\"must be {left.shape}: given {right.shape}\"\n\u001b[32m   8172\u001b[39m                     )\n",
      "\u001b[31mValueError\u001b[39m: Unable to coerce to DataFrame, shape must be (202, 1): given (444, 1)"
     ]
    }
   ],
   "source": [
    "# trying to predict more recent ones\n",
    "X, y = get_recent_apple_stock_split(DAYS_LAG)\n",
    "\n",
    "\n",
    "X_scaled = scaler_X.transform(X)\n",
    "predictions = scaler_Y.inverse_transform(grid_search.best_estimator_.predict(X_scaled).reshape(-1,1))\n",
    "\n",
    "mae = mean_absolute_error(y, predictions)\n",
    "mse = mean_squared_error(y, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.abs((y - predictions)/y_test).mean() * 100\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"mape: {mape}\")\n",
    "#graph_normal(predictions, y, \"recent data predicitons\")\n",
    "graph_line(predictions, y, f\"recent data predicitons for model with {DAYS_LAG} days lagged\")\n",
    "get_num_correct_direction_difference(predictions,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
